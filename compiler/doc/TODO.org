* newhope - Arm M4 (compcert C + low-level code)

* register allocation: consecutive registers

  foo [ri,ri+1,ri+2,ri+3] mem
  => where ri are consecutive registers

  instr %r %s
  %r = any, %s = %r + 1
  or %r even and %s odd

ARM: ldrd r
  example (give one register, others are infered)

* machine description

/*
machine amd64:


*/ 

//
fn addc64(x : reg u64, y : reg u64, c_in : reg u1)-> z : reg u64 * c_out : reg u1 =
  { python: addc64;
    amd64: asm/adcq y, z
           Eq(x,z)
           Fix(c_in=flg_carry)
           Fix(c_out=flg_carry)
           Clobber(flg_zero)
           ...
    
  }

fn addc64_all(x : reg u64, y : reg u64, c_in : reg u1)
  -> z : reg u64 * cf_out : reg u1 * zero_out : reg u1 {
}

* deal better with params for python functions
* Kummer port
** Required vector instructions
*** _mm256_add_epi32          [X]
*** _mm256_mul_epi32          [X]
*** _mm256_mul_epu32          [X]
*** _mm256_set_epi32          [X]
*** _mm256_shuffle_epi32      [X]
*** _mm256_blendv_epi8        [ ]
    Blend packed 8-bit integers from a and b using mask, and store the
    results in dst.
    
    FOR j := 0 to 31
	i := j*8
	IF mask[i+7]
		dst[i+7:i] := b[i+7:i]
	ELSE
		dst[i+7:i] := a[i+7:i]
	FI
    ENDFOR
    dst[MAX:256] := 0
    
*** _mm256_add_epi64          [X]
*** _mm256_slli_epi64         [ ]
    Shift packed 64-bit integers in a left by imm8 while shifting in
    zeros, and store the results in dst.
*** _mm256_srli_epi64         [ ]
    Shift packed 64-bit integers in a right by imm8 while shifting in
    zeros, and store the results in dst.
*** _mm256_permute4x64_epi64  [X]

    Shuffle 64-bit integers in a across lanes using the control in
    imm8, and store the results in dst.
    
    
